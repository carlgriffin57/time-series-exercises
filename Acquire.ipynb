{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using the code from the lesson as a guide and the REST API from https://python.zach.lol/api/v1/items as we did in the lesson, create a dataframe named items that has all of the data for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://python.zach.lol/api/v1/items')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = response.json()\n",
    "print(type(items))\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://python.zach.lol'\n",
    "\n",
    "api_url = base_url + '/api/v1/'\n",
    "response = requests.get(api_url + 'items')\n",
    "data = response.json()\n",
    "    \n",
    "# create list from 1st page\n",
    "output = data['payload']['items']\n",
    "\n",
    "# loop through the pages and add to list\n",
    "while data['payload']['next_page'] != None:\n",
    "    \n",
    "    response = requests.get(base_url + data['payload']['next_page'])\n",
    "    data = response.json()\n",
    "    output.extend(data['payload']['items'])\n",
    "    \n",
    "df_items = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Do the same thing, but for stores (https://python.zach.lol/api/v1/stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://python.zach.lol/api/v1/stores')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = response.json()\n",
    "print(type(stores))\n",
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stores = pd.DataFrame(stores['payload']['stores'])\n",
    "df_stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data for sales (https://python.zach.lol/api/v1/sales). There are a lot of pages of data here, so your code will need to be a little more complex. Your code should continue fetching data from the next page until all of the data is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://python.zach.lol/api/v1/sales')\n",
    "\n",
    "data = response.json()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max_page: %s' % data['payload']['max_page'])\n",
    "print('next_page: %s' % data['payload']['next_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://python.zach.lol'\n",
    "\n",
    "api_url = base_url + '/api/v1/'\n",
    "response = requests.get(api_url + 'sales')\n",
    "data = response.json()\n",
    "    \n",
    "# create list from 1st page\n",
    "output = data['payload']['sales']\n",
    "\n",
    "# loop through the pages and add to list\n",
    "while data['payload']['next_page'] != None:\n",
    "    \n",
    "    response = requests.get(base_url + data['payload']['next_page'])\n",
    "    data = response.json()\n",
    "    output.extend(data['payload']['sales'])\n",
    "    \n",
    "df_sales = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data in your files to local csv files so that it will be faster to access in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.to_csv(\"items_df.csv\")\n",
    "df_stores.to_csv(\"stores_df.csv\")\n",
    "df_sales.to_csv(\"sales_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the data from your three separate dataframes into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join sales and stores\n",
    "df = pd.merge(df_sales, df_stores, left_on='store', right_on='store_id').drop(columns={'store'})\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join the joined df to the items\n",
    "df = pd.merge(df, df_items, left_on='item', right_on='item_id').drop(columns={'item'})\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"joined_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire the Open Power Systems Data for Germany, which has been rapidly expanding its renewable energy production in recent years. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for 2006-2017. You can get the data here: https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'\n",
    "\n",
    "open_power_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_power_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_power_df.to_csv(\"open_power_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure all the work that you have done above is reproducible. That is, you should put the code above into separate functions in the acquire.py file and be able to re-run the functions and get the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_data():\n",
    "    '''\n",
    "    This function reads in sales data from a url, writes data to\n",
    "    a csv file if a local file does not exist, and returns a df.\n",
    "    '''\n",
    "    if os.path.isfile('sales_df.csv'):\n",
    "        # Reads the csv saved from above, and assigns to the df variable\n",
    "        df_sales = pd.read_csv('items_df.csv', index_col=0)    \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        base_url = 'https://python.zach.lol'\n",
    "\n",
    "        api_url = base_url + '/api/v1/'\n",
    "        response = requests.get(api_url + 'items')\n",
    "        data = response.json()\n",
    "    \n",
    "        # create list from 1st page\n",
    "        output = data['payload']['items']\n",
    "\n",
    "        # loop through the pages and add to list\n",
    "        while data['payload']['next_page'] != None:\n",
    "    \n",
    "            response = requests.get(base_url + data['payload']['next_page'])\n",
    "            data = response.json()\n",
    "            output.extend(data['payload']['items'])\n",
    "    \n",
    "        df_items = pd.DataFrame(output)\n",
    "        \n",
    "    return df_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stores_data():\n",
    "    '''\n",
    "    This function reads in stores data from a url, writes data to\n",
    "    a csv file if a local file does not exist, and returns a df.\n",
    "    '''\n",
    "    if os.path.isfile('stores_df.csv'):\n",
    "        \n",
    "        # If csv file exists read in data from csv file.\n",
    "        df_items = pd.read_csv('stores_df.csv', index_col=0)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        base_url = 'https://python.zach.lol'\n",
    "        api_url = base_url + '/api/v1/stores'\n",
    "        response = requests.get(api_url)\n",
    "        data = response.json()\n",
    "        df_items = pd.DataFrame(data['payload']['stores'])\n",
    "        \n",
    "        # Cache data\n",
    "        df.to_csv('zillow_df.csv')\n",
    "        \n",
    "    return df_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales_data():\n",
    "    '''\n",
    "    This function reads in sales data from a url, writes data to\n",
    "    a csv file if a local file does not exist, and returns a df.\n",
    "    '''\n",
    "    \n",
    "    if os.path.isfile('sales_df.csv'):\n",
    "        df_sales = pd.read_csv('sales_df.csv', index_col=0)    \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        base_url = 'https://python.zach.lol'\n",
    "\n",
    "        api_url = base_url + '/api/v1/'\n",
    "        response = requests.get(api_url + 'sales')\n",
    "        data = response.json()\n",
    "    \n",
    "        # create list from 1st page\n",
    "        output = data['payload']['sales']\n",
    "\n",
    "        # loop through the pages and add to list\n",
    "        while data['payload']['next_page'] != None:\n",
    "    \n",
    "            response = requests.get(base_url + data['payload']['next_page'])\n",
    "            data = response.json()\n",
    "            output.extend(data['payload']['sales'])\n",
    "    \n",
    "        df_sales = pd.DataFrame(output)\n",
    "        \n",
    "    return df_sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joined():\n",
    "    '''\n",
    "    This function joins the sales, stores and items dataframes into one\n",
    "    single data frame and return that df.\n",
    "    '''\n",
    "    if os.path.isfile('joined_sales_df.csv'):\n",
    "        joined_sales_df = pd.read_csv('joined_df.csv', index_col=0) \n",
    "    else:\n",
    "        df_items = get_items()\n",
    "        df_stores = get_stores()\n",
    "        df_sales = get_sales()\n",
    "    \n",
    "        # left join sales and stores\n",
    "        df = pd.merge(df_sales, df_stores, left_on='store', right_on='store_id').drop(columns={'store'})\n",
    "    \n",
    "        # left join the joined df to the items\n",
    "        df = pd.merge(df, df_items, left_on='item', right_on='item_id').drop(columns={'item'})\n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_open_power_data():\n",
    "    '''\n",
    "    This function reads in Open Power Systems Data csv file for Germany, writes data to\n",
    "    a csv file if a local file does not exist, and returns a df.\n",
    "    '''\n",
    "    if os.path.isfile('open_power_df.csv'):\n",
    "        open_power_df = pd.read_csv('open_power_df.csv', index_col=0)    \n",
    "        \n",
    "    else:\n",
    "        url = 'https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'\n",
    "        open_power_df = pd.read_csv(url)\n",
    "    \n",
    "        \n",
    "    return open_power_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = acquire.get_joined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_power_df = acquire.get_open_power_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
